---
title: "LCClean"
author: "Eric Voss"
date: "9/21/2020"
output: html_document
---

```{r loadPackagesAndData, include=FALSE}
if(!require(tidyverse)){install.packages('tidyverse');require(tidyverse)}
options(dplyr.summarise.inform = FALSE)
if(!require(caret)){install.packages('caret');require(caret)}
if(!require(ranger)){install.packages('ranger');require(ranger)}
if(!require(xgboost)){install.packages('xgboost');require(xgboost)}
if(!require(pROC)){install.packages('pROC');require(pROC)}
dataSet = read_csv('LoanStats3a.csv')
```

```{r EDA}
dim(dataSet)
table(sapply(dataSet[1,],class))
```
We have 111 features and roughly 42,000 observations. However, some of these observations and/or features might not be useful, so we need to take a closer look.

Let's visualize missing values in this data set.
```{r missing}
ggplot_missing <- function(x){
	if(!require(reshape2)){warning('you need to install reshape2')}
	require(reshape2)
	#### This function produces a plot of the missing data pattern
	#### in x.  It is a modified version of a function in the 'neato' package
  x %>% 
    is.na %>%
    melt %>%
    ggplot(data = .,
           aes(x = Var2,
               y = Var1)) +
    geom_raster(aes(fill = value)) +
    scale_fill_grey(name = "",
                    labels = c("Present","Missing")) +
    theme_minimal() + 
    theme(axis.text.x  = element_text(angle=45, vjust=0.5)) + 
    labs(x = "Variables in Dataset",
         y = "Rows / observations")
}
ggplot_missing(dataSet)
```

There's quite a bit of missing data there - I'll remove features with entirely missing data, as I can't do anything with those, and then look at what's left.
```{r}
dataSet = dataSet[,colSums(is.na(dataSet))<nrow(dataSet)]
table(sapply(dataSet,class))
```

My goal with this project: let's take a look at "purpose", which looks to be a factor with 15 levels, and see if we can use other features to build a classifier for it. This could be useful for, say, targeted advertising to potential customers which specifically mentions loan purposes which might be relevant to them. To that end, I'm going to take a subset of this data which excludes features that wouldn't be available for prospects who aren't yet customers. Some of these fields, like loan amount, could be highly predictive, but wouldn't actually be useful in building this model from a business perspective.

```{r}
dataSetReduced = dataSet %>%
  select(purpose, home_ownership, annual_inc,delinq_2yrs,
         inq_last_6mths,mths_since_last_delinq,mths_since_last_record,open_acc,
         pub_rec,pub_rec_bankruptcies,revol_bal,revol_util,total_acc)
sapply(dataSetReduced, function(x)length(unique(x)))
sapply(dataSetReduced,function(x){sum(is.na(x))})
```

We have to decide what to do with these missing values in the data. Fortunately, most of these features have very few missing values, so removing those entries should have a minimal impact. 2 features stand out to me here - mths_since_last_record, and mths_since_last_delinq. I'd like to look at these features more closely.


```{r}
unique(dataSetReduced$mths_since_last_delinq)
unique(dataSetReduced$mths_since_last_record)
```

Since these features measure the length of time since the last event of interest (delinquincies and public records), the missing values seem to indicate that the event has never happened. I will be recoding these into qualititative features with 2 levels to indicate if the individual has ever had a delinquincy/public record.

```{r}
m = is.na(dataSetReduced$mths_since_last_delinq)
dataSetReduced$mths_since_last_delinq[m==TRUE] = 0
dataSetReduced$mths_since_last_delinq[m==FALSE] = 1
n = is.na(dataSetReduced$mths_since_last_record)
dataSetReduced$mths_since_last_record[n==TRUE] = 0
dataSetReduced$mths_since_last_record[n==FALSE] = 1
```

Now, I'll drop the rest of our missing value records, and do some conversion/fixing of data types:
```{r}
dataSetReduced = drop_na(dataSetReduced)

#Remove the % sign and convert to numeric for revol_util
dataSetReduced$revol_util = gsub('.{1}$', '', dataSetReduced$revol_util)
dataSetReduced$revol_util = (as.numeric(dataSetReduced$revol_util))
#Convert purpose to factor and use one-hot encoding on home_ownership
dataSetReduced$home_ownership = as.factor(dataSetReduced$home_ownership)
dataSetReducedTemp = dataSetReduced[,-1]
dmy <- dummyVars(" ~ .", data = dataSetReducedTemp)
dataSetReducedTemp <- data.frame(predict(dmy, newdata = dataSetReducedTemp))
dataSetReducedTemp$purpose = as.factor(dataSetReduced$purpose)
dataSetReduced = dataSetReducedTemp
summary(dataSetReduced$purpose)
```

I'm noticing here that we have a somwhat imbalanced classifier - around half our records have a "debt consolidation" classification. This may present an issue going forward.

Applying a training/test split:
```{r}
Y = dataSetReduced$purpose
X = select(dataSetReduced, -purpose)
set.seed(1)
trainSplit = createDataPartition(y = Y, p = 0.8, list = FALSE)

Ytrain = Y[trainSplit]
Xtrain = X[trainSplit,]
Ytest  = Y[-trainSplit]
Xtest  = X[-trainSplit,]
training = dataSetReduced[ trainSplit,]
testing = dataSetReduced[-trainSplit,]
```

```{r}
trControl = trainControl(method = "cv", number = 5)
```

First, I will try out KNN to classify Purpose. This requires some preprocessing.
```{r}
tuneGrid = expand.grid(k = c(1,2,10,50,100,150,200))
knnOut = train(x = Xtrain, y = Ytrain, method = "knn", tuneGrid = tuneGrid, trControl = trControl,preProcess = c("center","scale"))
```

Looking at the results from knn:
```{r}
YhatKnn = predict(knnOut, Xtest)
table(YhatKnn, Ytest)
```

Indeed, the imbalanced classifier is an issue - KNN is more or less predicting debt_conolidation for everything. In addition, we probably have too few data points relative to the number of features for KNN to be effective. I will try a decision tree method going forward, which may handle this issue better.

First, I'm going to rework the supervisor to narrow my focus into classifying between "debt consolidation" and "single purpose" (e.g. home repair, education, etc.) loans. After some consideration of what we might be trying to acheive with this project, I decided that this split would be much easier to use while still providing considerable business value. The problem of marketing debt consolidation products to debt-laden consumers is, in some ways, the polar opposite of trying to market products designed to increase the purchasing power of consumers without as much existing debt to worry about, so distinguishing between these two categories of consumers is critical.
```{r}
levels(Ytrain)[levels(Ytrain)!="debt_consolidation"] = "single_purpose"
levels(Ytest)[levels(Ytest)!="debt_consolidation"] = "single_purpose"
Ytrain = relevel(Ytrain,"debt_consolidation")
Ytest = relevel(Ytest,"debt_consolidation")
```

Here, I'm trying a pruned classification tree
```{r}
tuneGrid = expand.grid(cp = c(0.0001,0.001, 0.01, 0.1))
rpartOut = train(x = Xtrain, y = Ytrain,
                  method = "rpart",
                  tuneGrid = tuneGrid,
                  trControl = trControl)
plot(rpartOut$finalModel,margin= rep(.1,4))
text(rpartOut$finalModel, cex = 0.4, digits = 1)
```


Next, I'm going to try a Random Forest method, followed by a boosting method.
```{r}
set.seed(1)
tuneGridRf     = data.frame(mtry = round(sqrt(ncol(Xtrain))))
rfOut      = train(x = Xtrain, y = Ytrain,
                   method = "rf",
                   tuneGrid = tuneGridRf,
                   trControl = trControl)
```


```{r boost, cache = TRUE}
set.seed(1)
tuneGrid = data.frame('nrounds'=c(100,150,200),
                      'max_depth' = 6,
                      'eta' = .01,
                      'gamma' = 0,
                      'colsample_bytree' = 1,
                      'min_child_weight' = 0,
                      'subsample' = .5)
boostOut   = train(x = Xtrain, y = Ytrain,
                   method = "xgbTree", verbose = 0,
                   tuneGrid = tuneGrid,
                   trControl = trControl)
```

Now let's take a look at these results with some ROC curves. I'm also going to look at various decision thresholds for each model.
```{r}
YhatRfProbs = predict(rfOut, Xtest,type="prob")
YhatRPartProbs = predict(rpartOut, Xtest,type="prob")
YhatBoostProbs = predict(boostOut, Xtest,type="prob")

rocCurve = roc(Ytest, YhatRfProbs$single_purpose)
rocCurve2 = roc(Ytest, YhatRPartProbs$single_purpose)
rocCurve3 = roc(Ytest, YhatBoostProbs$single_purpose)

plot(rocCurve, legacy.axes=TRUE,print.thres=c(0.3,0.44,0.5),col='black',main = "thresholds = Random Forest")
lines(rocCurve2, col = 'red')
lines(rocCurve3, col = 'green')
legend(x=0,y = 0.5,legend=c("Class. Tree","Random Forest","Xgboost"),col=c("red","black","green"),lty=1,cex=0.8)

plot(rocCurve2, legacy.axes=TRUE,print.thres=c(0.432,0.6),col='red', main = "thresholds = Class. Tree")
lines(rocCurve, col = 'black')
lines(rocCurve3, col = 'green')
legend(x=0,y = 0.5,legend=c("Class. Tree","Random Forest","Xgboost"),col=c("red","black","green"),lty=1,cex=0.8)

plot(rocCurve3, legacy.axes=TRUE,print.thres=c(0.44,0.47,0.5),col='green',main = "thresholds = Xgboost")
lines(rocCurve2, col = 'red')
lines(rocCurve, col = 'black')
legend(x=0,y = 0.5,legend=c("Class. Tree","Random Forest","Xgboost"),col=c("red","black","green"),lty=1,cex=0.8)
```

These classifiers all perform fairly similarly. For this hypothetical business problem, I am assuming the marginal cost of trying to sell a debt consolidation product to someone who is not interested is fairly low, so I'm going to use the ROC curve above to choose a lower threshold than the default of 0.5.

```{r}

YhatRf = as.factor(ifelse(YhatRfProbs[,2] >= 0.44,"debt_consolidation","single_purpose")) #Get Yhats using threshold of 0.44 instead
YhatRpart = as.factor(ifelse(YhatRPartProbs[,1] >= 0.432,"debt_consolidation","single_purpose"))
YhatBoost = as.factor(ifelse(YhatBoostProbs[,2] >= 0.47,"debt_consolidation","single_purpose"))

confusionMatrix(reference = Ytest, data = YhatRf)
confusionMatrix(reference = Ytest, data = YhatRpart)
confusionMatrix(reference = Ytest, data = YhatBoost)
```

Now we're getting much more useful results with these models.

I would like to also look at which feature importance to see which data is most important in making these predictions.
```{r importance}
boostImportance = xgb.importance(model = boostOut$finalModel) 
rfImportance = data.frame(rfOut$finalModel$importance)
rpartImportance = data.frame(rpartOut$finalModel$variable.importance/sum(rpartOut$finalModel$variable.importance))

boostImportance
rfImportance
rpartImportance
```
All three models agree that the 3 most overwhelmingly important features are revol_bal, revol_util, and annual_inc. This makes a lot of sense: revol_bal and revol_util tell us an individual's revolving balance and their balance relative to all available credit, respectively. These should be strongly predictive of an individual's need for debt consolidation. Income also would heavily impact the relative burden imposed by a given level of debt, so it's also expected that annual income is a highly important feature.

Finally, I will choose a model to export which will be used in a Shiny app to help hypothetical employees of a company decide whether or not to send debt consolidation marketing materials to a potential customer. Based on its accuracy and high sensitivity, I will use the Xgboost model.

```{r}
saveRDS(boostOut,"./final_model.rds")
```